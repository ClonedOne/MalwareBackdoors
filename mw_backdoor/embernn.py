import os

import shap
import joblib
import tensorflow as tf

from keras.models import Model
from keras.optimizers import SGD
from keras.models import load_model
from keras.layers import Dense, BatchNormalization, Activation, Input, Dropout
from sklearn.preprocessing import StandardScaler


class EmberNN(object):
    def __init__(self, n_features):
        self.n_features = n_features
        self.normal = StandardScaler()
        self.model = self.build_model()
        self.exp = None

        lr = 0.1
        momentum = 0.9
        decay = 0.000001
        opt = SGD(lr=lr, momentum=momentum, decay=decay)

        self.model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])

    def fit(self, X, y):
        self.normal.fit(X)
        self.model.fit(self.normal.transform(X), y, batch_size=512, epochs=10)

    def predict(self, X):
        return self.model.predict(self.normal.transform(X), batch_size=512)

    def build_model(self):
        model = None
        with tf.device('/cpu:0'):
            input1 = Input(shape=(self.n_features,))
            dense1 = Dense(4000, activation='relu')(input1)
            norm1 = BatchNormalization()(dense1)
            drop1 = Dropout(0.5)(norm1)
            dense2 = Dense(2000, activation='relu')(drop1)
            norm2 = BatchNormalization()(dense2)
            drop2 = Dropout(0.5)(norm2)
            dense3 = Dense(100, activation='relu')(drop2)
            norm3 = BatchNormalization()(dense3)
            drop3 = Dropout(0.5)(norm3)
            dense4 = Dense(1)(drop3)
            out = Activation('sigmoid')(dense4)
            model = Model(inputs=[input1], outputs=[out])
        return model

    def explain(self, X_back, X_exp, n_samples=100):
        if self.exp is None:
            self.exp = shap.GradientExplainer(self.model, self.normal.transform(X_back))
        return self.exp.shap_values(self.normal.transform(X_exp), nsamples=n_samples)

    def save(self, save_path, file_name='ember_nn'):
        # Save the trained scaler so that it can be reused at test time
        joblib.dump(self.normal, os.path.join(save_path, file_name + '_scaler.pkl'))

        save_model = self.model
        save_model.save(os.path.join(save_path, file_name + '.h5'))

    def load(self, save_path, file_name):
        # Load the trained scaler
        self.normal = joblib.load(os.path.join(save_path, file_name + '_scaler.pkl'))

        self.model = load_model(os.path.join(save_path, file_name + '.h5'))
